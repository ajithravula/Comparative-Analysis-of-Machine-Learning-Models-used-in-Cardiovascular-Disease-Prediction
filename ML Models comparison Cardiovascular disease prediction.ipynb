{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baa1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from prettytable import PrettyTable\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f3515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\processed.cleveland.data\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ecb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['age', 'sex', 'chest pain', 'blood pressure', 'cholestrol','blood sugar', \n",
    "              'restecg', 'heart rate(max)', 'exercise induced agina', 'oldpeak', 'slope', 'num vessels', 'thalesemia', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235053eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a572f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c83348",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df.drop(df.index[df[col] == '?'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bdd51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num vessels'] = pd.to_numeric(df['num vessels'])\n",
    "df['thalesemia'] = pd.to_numeric(df['thalesemia'])\n",
    "df['target'] = df['target'].replace({4:1,2:1,3:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293b92e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c7199",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df.corr()\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Correlation Heatmap ')\n",
    "ax = sns.heatmap(correlation, square=True, annot=True, fmt='.2f', linecolor='white')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=30)           \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54a46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target',axis = 1)\n",
    "Y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d533d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf9759",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "scale.fit(x_train)\n",
    "x_train = scale.transform(x_train)\n",
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78bd989",
   "metadata": {},
   "source": [
    "### Classification Models Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c063a8",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18748ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train, y_train)\n",
    "y_log_reg_pred = log_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace6dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat_lr = confusion_matrix(y_true=y_test, y_pred=y_log_reg_pred)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(con_mat_lr, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for x in range(con_mat_lr.shape[0]):\n",
    "    for y in range(con_mat_lr.shape[1]):\n",
    "        ax.text(x=y, y=x,s=con_mat_lr[x, y], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Prediction Classes', fontsize=18)\n",
    "plt.ylabel('Actual Classes', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b5dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_log_reg_pred), \": is the confusion matrix\")\n",
    "print(classification_report(y_test, y_log_reg_pred))\n",
    "print(accuracy_score(y_test, y_log_reg_pred), \": is the accuracy score\")\n",
    "print(precision_score(y_test,y_log_reg_pred), \": is the precision score\")\n",
    "print(recall_score(y_test, y_log_reg_pred), \": is the recall score\")\n",
    "print(f1_score(y_test, y_log_reg_pred), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb3008",
   "metadata": {},
   "source": [
    "### Logistic Regression Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318db917",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter' : [100, 1000, 2500, 5000]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e81b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(log_reg, param_grid=param_grid, verbose = True, cv = 3, n_jobs = -1)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d56905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee516bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df776f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat_lr = confusion_matrix(y_true=y_test, y_pred=clf_lr_pred)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(con_mat_lr, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for x in range(con_mat_lr.shape[0]):\n",
    "    for y in range(con_mat_lr.shape[1]):\n",
    "        ax.text(x=y, y=x,s=con_mat_lr[x, y], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Prediction Classes', fontsize=18)\n",
    "plt.ylabel('Actual Classes', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b770e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, clf_lr_pred), \": is the confusion matrix\")\n",
    "print(classification_report(y_test, clf_lr_pred))\n",
    "print(accuracy_score(y_test, clf_lr_pred), \": is the accuracy score\")\n",
    "print(precision_score(y_test, clf_lr_pred), \": is the precision score\")\n",
    "print(recall_score(y_test, clf_lr_pred), \": is the recall score\")\n",
    "print(f1_score(y_test, clf_lr_pred), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237152e",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee345c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_bay = GaussianNB()\n",
    "nav_bay.fit(x_train,y_train)\n",
    "y_nav_bay_pred = nav_bay.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d26d25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat_nav = confusion_matrix(y_true=y_test, y_pred=y_nav_bay_pred)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(con_mat_nav, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for x in range(con_mat_nav.shape[0]):\n",
    "    for y in range(con_mat_nav.shape[1]):\n",
    "        ax.text(x=y, y=x,s=con_mat_nav[x,y], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Prediction Classes', fontsize=18)\n",
    "plt.ylabel('Actual Classes', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff76cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction scores before hyperparameter tuning\n",
    "print(confusion_matrix(y_test, y_nav_bay_pred), \": is the confusion matrix\")\n",
    "print(classification_report(y_test, y_nav_bay_pred))\n",
    "print(accuracy_score(y_test, y_nav_bay_pred), \": is the accuracy score\")\n",
    "print(precision_score(y_test, y_nav_bay_pred), \": is the precision score\")\n",
    "print(recall_score(y_test, y_nav_bay_pred), \": is the recall score\")\n",
    "print(f1_score(y_test, y_nav_bay_pred), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd3f454",
   "metadata": {},
   "source": [
    "### Naive Bayes Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1875894",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_method = RepeatedStratifiedKFold(n_splits=5, \n",
    "                                    n_repeats=3, \n",
    "                                    random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bbd31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b307b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "nb_classifier = GaussianNB()\n",
    "gs_NB = GridSearchCV(estimator=nb_classifier, \n",
    "                     param_grid=params_NB, \n",
    "                     cv=cv_method,\n",
    "                     verbose=1, \n",
    "                     scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d80730",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_transformed = PowerTransformer().fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155745a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_NB.fit(Data_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f3f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_NB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0521d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_NB.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a17d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB(var_smoothing = 0.43)\n",
    "nb.fit(x_train,y_train)\n",
    "gs_nb_pred = nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4073a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_matrix_nav = confusion_matrix(y_true=y_test, y_pred=gs_nb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28137d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(con_matrix_nav, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for x in range(con_matrix_nav.shape[0]):\n",
    "    for y in range(con_matrix_nav.shape[1]):\n",
    "        ax.text(x=y, y=x,s=con_matrix_nav[x, y], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Prediction Classes', fontsize=18)\n",
    "plt.ylabel('Actual Classes', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac5311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction scores after hyperparameter tuning\n",
    "print(confusion_matrix(y_test, gs_nb_pred), \": is the confusion matrix\")\n",
    "print(classification_report(y_test, gs_nb_pred))\n",
    "print(accuracy_score(y_test, gs_nb_pred), \": is the accuracy score\")\n",
    "print(precision_score(y_test, gs_nb_pred), \": is the precision score\")\n",
    "print(recall_score(y_test, gs_nb_pred), \": is the recall score\")\n",
    "print(f1_score(y_test, gs_nb_pred), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdac873",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d833e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_vec = svm.SVC(kernel='linear')\n",
    "sup_vec.fit(x_train, y_train)\n",
    "y_pred_sup_vec = sup_vec.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca02e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat_sup = confusion_matrix(y_true=y_test, y_pred=y_pred_sup_vec)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(con_mat_sup, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for x in range(con_mat_sup.shape[0]):\n",
    "    for y in range(con_mat_sup.shape[1]):\n",
    "        ax.text(x=y, y=x,s=con_mat_sup[x, y], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Prediction Classes', fontsize=18)\n",
    "plt.ylabel('Actual Classes', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ababbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction scores before hyperparameter tuning\n",
    "print(confusion_matrix(y_test, y_pred_sup_vec), \": is the confusion matrix\")\n",
    "print(classification_report(y_test, y_pred_sup_vec))\n",
    "print(accuracy_score(y_test, y_pred_sup_vec), \": is the accuracy score\")\n",
    "print(precision_score(y_test, y_pred_sup_vec), \": is the precision score\")\n",
    "print(recall_score(y_test, y_pred_sup_vec), \": is the recall score\")\n",
    "print(f1_score(y_test, y_pred_sup_vec), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce29fb2a",
   "metadata": {},
   "source": [
    "### SVM Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02414705",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C' : [0.1,1, 10, 100],\n",
    "             'gamma' : [1, 0.1, 0.01, 0.001],\n",
    "             'kernel' : ['rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d5286",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_grid = GridSearchCV(svm.SVC(), param_grid, scoring = 'accuracy', refit = True, verbose = 4, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7223a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6ffe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3c23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca410cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pred_grid = SVM_grid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f218963",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_matrix_sup = confusion_matrix(y_true=y_test, y_pred=svm_pred_grid)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(con_matrix_sup, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for x in range(con_matrix_sup.shape[0]):\n",
    "    for y in range(con_matrix_sup.shape[1]):\n",
    "        ax.text(x=y, y=x,s=con_matrix_sup[x, y], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Prediction Classes', fontsize=18)\n",
    "plt.ylabel('Actual Classes', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e22296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, svm_pred_grid), \": is the confusion matrix\")\n",
    "print(classification_report(y_test, svm_pred_grid))\n",
    "print(accuracy_score(y_test, svm_pred_grid), \": is the accuracy score\")\n",
    "print(precision_score(y_test, svm_pred_grid), \": is the precision score\")\n",
    "print(recall_score(y_test, svm_pred_grid), \": is the recall score\")\n",
    "print(f1_score(y_test, svm_pred_grid), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2229605",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bdbfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neig = KNeighborsClassifier()\n",
    "k_neig.fit(x_train,y_train)\n",
    "y_knn_pred=k_neig.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc774e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat_knn = confusion_matrix(y_true=y_test, y_pred=y_knn_pred)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(con_mat_knn, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for x in range(con_mat_knn.shape[0]):\n",
    "    for y in range(con_mat_knn.shape[1]):\n",
    "        ax.text(x=y, y=x,s=con_mat_knn[x, y], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Prediction Classes', fontsize=18)\n",
    "plt.ylabel('Actual Classes', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0251aa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_knn_pred), \": is the confusion matrix\")\n",
    "print(classification_report(y_test, y_knn_pred))\n",
    "print(accuracy_score(y_test, y_knn_pred), \": is the accuracy score\")\n",
    "print(precision_score(y_test, y_knn_pred), \": is the precision score\")\n",
    "print(recall_score(y_test, y_knn_pred), \": is the recall score\")\n",
    "print(f1_score(y_test, y_knn_pred), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29717ef2",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ad3fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = {'n_neighbors' : np.arange(1,50)}\n",
    "knn_gs = KNeighborsClassifier()\n",
    "knn_grid = GridSearchCV(knn_gs, gs, cv = 10)\n",
    "knn_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca767a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c80be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557afeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neig = KNeighborsClassifier(n_neighbors = 15)\n",
    "k_neig.fit(x_train,y_train)\n",
    "knn_pred=k_neig.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33717cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_matrix_knn = confusion_matrix(y_true=y_test, y_pred=knn_pred)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(con_matrix_knn, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for x in range(con_matrix_knn.shape[0]):\n",
    "    for y in range(con_matrix_knn.shape[1]):\n",
    "        ax.text(x=y, y=x,s=con_matrix_knn[x, y], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Prediction Classes', fontsize=18)\n",
    "plt.ylabel('Actual Classes', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c13fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, knn_pred), \": is the confusion matrix\")\n",
    "print(classification_report(y_test,  knn_pred))\n",
    "print(accuracy_score(y_test,  knn_pred), \": is the accuracy score\")\n",
    "print(precision_score(y_test,  knn_pred), \": is the precision score\")\n",
    "print(recall_score(y_test,  knn_pred), \": is the recall score\")\n",
    "print(f1_score(y_test,  knn_pred), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6782dc",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree = DecisionTreeClassifier()\n",
    "dec_tree.fit(x_train,y_train)\n",
    "y_pred_dec_tree = dec_tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87c070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat_dc = confusion_matrix(y_true=y_test, y_pred=y_pred_dec_tree)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(con_mat_dc, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for x in range(con_mat_dc.shape[0]):\n",
    "    for y in range(con_mat_dc.shape[1]):\n",
    "        ax.text(x=y, y=x,s=con_mat_dc[x, y], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Prediction Classes', fontsize=18)\n",
    "plt.ylabel('Actual Classes', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6334b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred_dec_tree), \": is the confusion matrix\")\n",
    "print(classification_report(y_test, y_pred_dec_tree))\n",
    "print(accuracy_score(y_test,  y_pred_dec_tree), \": is the accuracy score\")\n",
    "print(precision_score(y_test,  y_pred_dec_tree), \": is the precision score\")\n",
    "print(recall_score(y_test,  y_pred_dec_tree), \": is the recall score\")\n",
    "print(f1_score(y_test, y_pred_dec_tree), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40944f2d",
   "metadata": {},
   "source": [
    "### Decision Tree Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593d2ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'criterion': ['gini', 'entropy'],\n",
    "              'min_samples_split': [2, 10, 20],\n",
    "              'max_depth': [5, 10, 20, 25, 30],\n",
    "              'min_samples_leaf': [1, 5, 10],\n",
    "              'max_leaf_nodes': [2, 5, 10, 20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb60ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "grid_search_cv = GridSearchCV(dt, param_grid, cv = 3, scoring = 'accuracy')\n",
    "grid_search_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1265bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbede4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hps, values in grid_search_cv.best_params_.items():\n",
    "  print(f\"{hps}: {values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c71899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = DecisionTreeClassifier(criterion = 'gini', max_depth = 5, \n",
    "                                    min_samples_leaf = 5, max_leaf_nodes = 10, min_samples_split = 2)\n",
    "best_model.fit(x_train, y_train)\n",
    "preds_dc = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102b4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_matrix_dc = confusion_matrix(y_true=y_test, y_pred=preds_dc)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(con_matrix_dc, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for x in range(con_matrix_dc.shape[0]):\n",
    "    for y in range(con_matrix_dc.shape[1]):\n",
    "        ax.text(x=y, y=x,s=con_matrix_dc[x, y], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Prediction Classes', fontsize=18)\n",
    "plt.ylabel('Actual Classes', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bdb8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, preds_dc), \": is the confusion matrix\")\n",
    "print(classification_report(y_test,  preds_dc))\n",
    "print(accuracy_score(y_test,  preds_dc), \": is the accuracy score\")\n",
    "print(precision_score(y_test,  preds_dc), \": is the precision score\")\n",
    "print(recall_score(y_test,  preds_dc), \": is the recall score\")\n",
    "print(f1_score(y_test,  preds_dc), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527090ea",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becf8b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_fos = RandomForestClassifier()\n",
    "ran_fos.fit(x_train,y_train)\n",
    "Y_rf_pred = ran_fos.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0879adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat_rf = confusion_matrix(y_true=y_test, y_pred=Y_rf_pred)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(con_mat_rf, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for x in range(con_mat_rf.shape[0]):\n",
    "    for y in range(con_mat_rf.shape[1]):\n",
    "        ax.text(x=y, y=x,s=con_mat_rf[x, y], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Predictions Classes', fontsize=18)\n",
    "plt.ylabel('Actual Classes', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d541d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, Y_rf_pred), \": is the confusion matrix\")\n",
    "print(classification_report(y_test,  Y_rf_pred))\n",
    "print(accuracy_score(y_test,  Y_rf_pred), \": is the accuracy score\")\n",
    "print(precision_score(y_test,  Y_rf_pred), \": is the precision score\")\n",
    "print(recall_score(y_test,  Y_rf_pred), \": is the recall score\")\n",
    "print(f1_score(y_test,  Y_rf_pred), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e3043",
   "metadata": {},
   "source": [
    "### Random Forest Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1aab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 300, 500, 800, 1200]\n",
    "max_depth = [5, 10, 15, 25, 30]\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "hyper_rf = dict(n_estimators = n_estimators, max_depth = max_depth, \n",
    "              min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23842322",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "gridrf = GridSearchCV(rf, hyper_rf, cv = 3, verbose = 1, n_jobs = -1)\n",
    "bestrf = gridrf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8355c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestrf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d861e770",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth = 30, min_samples_leaf = 1, min_samples_split = 100, n_estimators = 100)\n",
    "rf.fit(x_train, y_train)\n",
    "preds_rf = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e52930",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_matrix_rf = confusion_matrix(y_true=y_test, y_pred=preds_rf)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(con_matrix_rf, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for x in range(con_matrix_rf.shape[0]):\n",
    "    for y in range(con_matrix_rf.shape[1]):\n",
    "        ax.text(x=y, y=x,s=con_matrix_rf[x, y], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Prediction Classes', fontsize=18)\n",
    "plt.ylabel('Actual Classes', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ccb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, preds_rf), \": is the confusion matrix\")\n",
    "print(classification_report(y_test,  preds_rf))\n",
    "print(accuracy_score(y_test,  preds_rf), \": is the accuracy score\")\n",
    "print(precision_score(y_test,  preds_rf), \": is the precision score\")\n",
    "print(recall_score(y_test,  preds_rf), \": is the recall score\")\n",
    "print(f1_score(y_test,  preds_rf), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f055e672",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85abd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_boost = xgb.XGBClassifier()\n",
    "xg_boost.fit(x_train, y_train)\n",
    "y_pred_xg_boost = xg_boost.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat_xg = confusion_matrix(y_true=y_test, y_pred=y_pred_xg_boost)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(con_mat_xg, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for x in range(con_mat_xg.shape[0]):\n",
    "    for y in range(con_mat_xg.shape[1]):\n",
    "        ax.text(x=y, y=x,s=con_mat_xg[x, y], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Prediction Classes', fontsize=18)\n",
    "plt.ylabel('Actual Classes', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae780779",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred_xg_boost), \": is the confusion matrix\")\n",
    "print(classification_report(y_test,  y_pred_xg_boost))\n",
    "print(accuracy_score(y_test,  y_pred_xg_boost), \": is the accuracy score\")\n",
    "print(precision_score(y_test,  y_pred_xg_boost), \": is the precision score\")\n",
    "print(recall_score(y_test,  y_pred_xg_boost), \": is the recall score\")\n",
    "print(f1_score(y_test,  y_pred_xg_boost), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb44788",
   "metadata": {},
   "source": [
    "### XGBoost Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80430147",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'learning_rate': [0.001,0.01,0.1,0.25,0.5,0.4],\n",
    "         'max_depth': [1,2,3,4,5,6],\n",
    "         'max_features': [1,2,3,4,5,6],\n",
    "         'n_estimators': [20,40,50,70,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bfb39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_grid_search = GridSearchCV(xg_boost, param_grid = params, cv=5, n_jobs=-1, verbose = True)\n",
    "XG_grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e47d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764026b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_clf = xgb.XGBClassifier(learning_rate = 0.1, max_depth = 1, max_features = 1, n_estimators = 100)\n",
    "XG_clf.fit(x_train, y_train)\n",
    "XG_clf_pred = XG_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_matrix_xg = confusion_matrix(y_true=y_test, y_pred=XG_clf_pred)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(con_matrix_xg, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for x in range(con_matrix_xg.shape[0]):\n",
    "    for y in range(con_matrix_xg.shape[1]):\n",
    "        ax.text(x=y, y=x,s=con_matrix_xg[x, y], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Prediction Classes', fontsize=18)\n",
    "plt.ylabel('Actual Classes', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97813e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, XG_clf_pred), \": is the confusion matrix\")\n",
    "print(classification_report(y_test,  XG_clf_pred))\n",
    "print(accuracy_score(y_test,  XG_clf_pred), \": is the accuracy score\")\n",
    "print(precision_score(y_test,  XG_clf_pred), \": is the precision score\")\n",
    "print(recall_score(y_test,  XG_clf_pred), \": is the recall score\")\n",
    "print(f1_score(y_test,  XG_clf_pred), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a50fcc",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf69f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adab = AdaBoostClassifier()\n",
    "adab.fit(x_train, y_train)\n",
    "adab_pred = adab.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81902c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat_adab = confusion_matrix(y_true=y_test, y_pred=adab_pred)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(con_mat_adab, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for x in range(con_mat_adab.shape[0]):\n",
    "    for y in range(con_mat_adab.shape[1]):\n",
    "        ax.text(x=y, y=x,s=con_mat_adab[x, y], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Prediction Classes', fontsize=18)\n",
    "plt.ylabel('Actual Classes', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b6d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, adab_pred), \": is the confusion matrix\")\n",
    "print(classification_report(y_test,  adab_pred))\n",
    "print(accuracy_score(y_test, adab_pred), \": is the accuracy score\")\n",
    "print(precision_score(y_test, adab_pred), \": is the precision score\")\n",
    "print(recall_score(y_test, adab_pred), \": is the recall score\")\n",
    "print(f1_score(y_test, adab_pred), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a2c67",
   "metadata": {},
   "source": [
    "### AdaBoost Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a1603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_clf = AdaBoostClassifier()\n",
    "search_grid={'n_estimators':[500,1000,2000],'learning_rate':[.001,0.01,.1]}\n",
    "ada_clf = GridSearchCV(estimator = adb_clf, param_grid = search_grid, cv=5, verbose=1, n_jobs=-1, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e817e75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7327ecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a09ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1035dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adab_clf_pred = ada_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d17e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_matrix_adab = confusion_matrix(y_true=y_test, y_pred=adab_clf_pred)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(con_matrix_adab, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for x in range(con_matrix_adab.shape[0]):\n",
    "    for y in range(con_matrix_adab.shape[1]):\n",
    "        ax.text(x=y, y=x,s=con_matrix_adab[x, y], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Prediction Classes', fontsize=18)\n",
    "plt.ylabel('Actual Classes', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa25476",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, adab_clf_pred), \": is the confusion matrix\")\n",
    "print(classification_report(y_test,  adab_clf_pred))\n",
    "print(accuracy_score(y_test, adab_clf_pred), \": is the accuracy score\")\n",
    "print(precision_score(y_test, adab_clf_pred), \": is the precision score\")\n",
    "print(recall_score(y_test, adab_clf_pred), \": is the recall score\")\n",
    "print(f1_score(y_test, adab_clf_pred), \": is the f1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5eee0e",
   "metadata": {},
   "source": [
    "### Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3003cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(11,activation='relu',input_dim=13))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfdd29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de9ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_NN = model.predict(x_test)\n",
    "r = [round(x[0]) for x in pred_NN]\n",
    "pred_NN = r\n",
    "print(accuracy_score(y_test,  pred_NN), \": is the accuracy score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8ca463",
   "metadata": {},
   "source": [
    "### Comparing performance metrics of all ML models without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7113a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytable = PrettyTable(['Algorithm_Name','Accuracy_Score','Precision_Score','Recall_score','F1_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b2bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytable.add_row(['Logistic Regression','0.90','0.90','0.83','0.87'])\n",
    "mytable.add_row(['Naive Bayes','0.93','1.0','0.83','0.90'])\n",
    "mytable.add_row(['Support Vector Machine','0.90','0.95','0.79','0.86'])\n",
    "mytable.add_row(['K Nearest Neighbors','0.88','0.84','0.88','0.86'])\n",
    "mytable.add_row(['Decision Tree','0.80','0.73','0.79','0.76'])\n",
    "mytable.add_row(['Random Forest','0.90','0.90','0.83','0.87'])\n",
    "mytable.add_row(['XGBoost','0.86','0.83','0.83','0.83'])\n",
    "mytable.add_row(['AdaBoost','0.83','0.82','0.75','0.78'])\n",
    "mytable.add_row(['Neural Networks','0.85','NA','NA','NA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1dd807",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mytable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf03643",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 0.1\n",
    "Algorithms = [\"LR\", \"NB\", \"SVM\", \"KNN\", \"DT\", \"RF\", \"XGB\", \"ADB\"]\n",
    "Accuracy_Score = [0.90,0.93,0.90,0.88,0.80,0.90,0.86,0.83]\n",
    "Precision_Score = [0.90,1.00,0.95,0.84,0.73,0.90,0.83,0.82]\n",
    "Recall_Score = [0.83,0.83,0.79,0.88,0.79,0.83,0.83,0.75]\n",
    "F1_Score = [0.87,0.90,0.86,0.86,0.76,0.87,0.83,0.78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6709163",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar1 = np.arange(len(Algorithms))\n",
    "bar2 = [i+w for i in bar1]\n",
    "bar3 = [i+w for i in bar2]\n",
    "bar4 = [i+w for i in bar3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5a55b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.bar(bar1, Accuracy_Score, w, label = 'Accuracy Score')\n",
    "plt.bar(bar2, Precision_Score, w, label = 'Precision Score')\n",
    "plt.bar(bar3, Recall_Score, w, label = 'Recall Score')\n",
    "plt.bar(bar4, F1_Score, w, label = 'F1 Score')\n",
    "plt.xlabel(\"Algorithms\", fontweight = 'bold', fontsize = 14)\n",
    "plt.ylabel(\"Scores\", fontweight = 'bold', fontsize = 14)\n",
    "plt.title(\"Performance Metrics Comparison of all classification models before Hyperparameter Tuning\", fontweight = 'bold', fontsize = 18)\n",
    "plt.xticks(bar1+w, Algorithms, fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.legend(loc = 'best', fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6441615",
   "metadata": {},
   "source": [
    "### Comparison of Performance Metrics of all ML models with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b6585",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmwht = PrettyTable(['Algorithm_Name','Accuracy_Score','Precision_Score','Recall_score','F1_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03182963",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmwht.add_row(['Logistic Regression','0.93','0.95','0.86','0.91'])\n",
    "pmwht.add_row(['Naive Bayes','0.93','1.0','0.83','0.90'])\n",
    "pmwht.add_row(['Support Vector Machine','0.92','1.0','0.79','0.88'])\n",
    "pmwht.add_row(['K Nearest Neighbor','0.87','0.86','0.79','0.83'])\n",
    "pmwht.add_row(['Decision Tree','0.80','0.80','0.67','0.72'])\n",
    "pmwht.add_row(['Random Forest','0.92','0.95','0.83','0.89'])\n",
    "pmwht.add_row(['XGBoost','0.90','0.91','0.83','0.87'])\n",
    "pmwht.add_row(['AdaBoost','0.93','0.95','0.88','0.91'])\n",
    "pmwht.add_row(['Neural Networks','0.85','NA','NA','NA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df7b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pmwht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5100393",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 0.15\n",
    "algorithms = [\"LR\", \"NB\", \"SVM\", \"KNN\", \"DT\", \"RF\", \"XGB\", \"ADB\"]\n",
    "accuracy_score = [0.93,0.93,0.92,0.87,0.80,0.92,0.90,0.93]\n",
    "precision_score = [0.95,1.0,1.0,0.86,0.80,0.95,0.91,0.95]\n",
    "recall_score = [0.86,0.83,0.79,0.79,0.67,0.83,0.83,0.88]\n",
    "f1_score = [0.91,0.90,0.88,0.83,0.72,0.89,0.87,0.91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7796b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_1 = np.arange(len(algorithms))\n",
    "bar_2 = [i+w for i in bar1]\n",
    "bar_3 = [i+w for i in bar2]\n",
    "bar_4 = [i+w for i in bar3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa029b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,10))\n",
    "plt.bar(bar_1, accuracy_score, w, label = 'Accuracy Score')\n",
    "plt.bar(bar_2, precision_score, w, label = 'Precision Score')\n",
    "plt.bar(bar_3, recall_score, w, label = 'Recall Score')\n",
    "plt.bar(bar_4, f1_score, w, label = 'F1 Score')\n",
    "plt.xlabel(\"Algorithms\", fontweight = 'bold', fontsize = 14)\n",
    "plt.ylabel(\"Scores\", fontweight = 'bold', fontsize = 14)\n",
    "plt.title(\"Performance metrics comparison of Classification models after hyperparameter tuning\", \n",
    "          fontweight = 'bold', fontsize = 20)\n",
    "plt.xticks(bar1+w, Algorithms, fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.legend(loc = 'best', fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a7be9c",
   "metadata": {},
   "source": [
    "### Graphical representation of Accuracy scores of all Classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb86adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Algorithms':['LR','NB','SVM','KNN','DT','RF','XGB','ADB','NN'],\n",
    "                   'Accuracy Scores': [0.93,0.93,0.92,0.87,0.80,0.92,0.90,0.93,0.85]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5188fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "splot=sns.barplot(x=\"Algorithms\",y=\"Accuracy Scores\",data=df1)\n",
    "plt.xlabel(\"Algorithms\", fontsize=14, fontweight = 'bold')\n",
    "plt.ylabel(\"Accuracy\", size=14, fontweight = 'bold')\n",
    "plt.title(\"Comparison of Accuracy of all Classification Algorithms\", fontsize = 18)\n",
    "plt.bar_label(splot.containers[0], fontsize = 10, fontweight = 'bold')\n",
    "plt.savefig(\"annotate_barplot_with_Matplotlib_bar_label_Python.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8570529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
